{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T20:19:54.892165Z",
     "start_time": "2020-08-31T20:07:06.060662Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D,MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense,BatchNormalization\n",
    "import chess\n",
    "\n",
    "def flatten(itr):\n",
    "    t = tuple()\n",
    "    for e in itr:\n",
    "        try:\n",
    "            t += flatten(e)\n",
    "        except:\n",
    "            t += (e,)\n",
    "    return t\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "class genetic_algorithm:\n",
    "        \n",
    "    def execute(pop_size,generations,threshold):\n",
    "        class Agent:\n",
    "            def __init__(self):\n",
    "                class neural_network:\n",
    "                    def __init__(self):\n",
    "                        model = Sequential()\n",
    "                        model.add(Dense(64, activation='relu', input_shape=(8,8,12)))\n",
    "                        model.add(Flatten())\n",
    "                        model.add(BatchNormalization())\n",
    "                        model.add(Dense(1,activation = 'sigmoid'))\n",
    "                        self.model = model\n",
    "                        self.weights = model.get_weights()\n",
    "                    def propagate(self,X):\n",
    "                        self.model.predict(X)\n",
    "                        return self.model.predict(X)\n",
    "                    \n",
    "                self.neural_network = neural_network()\n",
    "                self.fitness = 0\n",
    "            def __str__(self):\n",
    "                    return 'Loss: ' + str(self.fitness)\n",
    "        \n",
    "                \n",
    "        def generate_agents(population):\n",
    "            return [Agent() for _ in range(population)]\n",
    "        \n",
    "        def fitness(agents):\n",
    "            chess_dict = {\n",
    "                'p' : [1,0,0,0,0,0,0,0,0,0,0,0],\n",
    "                'P' : [0,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                'n' : [0,1,0,0,0,0,0,0,0,0,0,0],\n",
    "                'N' : [0,0,0,0,0,0,0,1,0,0,0,0],\n",
    "                'b' : [0,0,1,0,0,0,0,0,0,0,0,0],\n",
    "                'B' : [0,0,0,0,0,0,0,0,1,0,0,0],\n",
    "                'r' : [0,0,0,1,0,0,0,0,0,0,0,0],\n",
    "                'R' : [0,0,0,0,0,0,0,0,0,1,0,0],\n",
    "                'q' : [0,0,0,0,1,0,0,0,0,0,0,0],\n",
    "                'Q' : [0,0,0,0,0,0,0,0,0,0,1,0],\n",
    "                'k' : [0,0,0,0,0,1,0,0,0,0,0,0],\n",
    "                'K' : [0,0,0,0,0,0,0,0,0,0,0,1],\n",
    "                '.' : [0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "            }\n",
    "\n",
    "                \n",
    "            def make_matrix(board): \n",
    "                pgn = board.epd()\n",
    "                foo = []  \n",
    "                pieces = pgn.split(\" \", 1)[0]\n",
    "                rows = pieces.split(\"/\")\n",
    "                for row in rows:\n",
    "                    foo2 = []  \n",
    "                    for thing in row:\n",
    "                        if thing.isdigit():\n",
    "                            for i in range(0, int(thing)):\n",
    "                                foo2.append('.')\n",
    "                        else:\n",
    "                            foo2.append(thing)\n",
    "                    foo.append(foo2)\n",
    "                return foo\n",
    "\n",
    "            def translate(matrix,chess_dict):\n",
    "                rows = []\n",
    "                for row in matrix:\n",
    "                    terms = []\n",
    "                    for term in row:\n",
    "                        terms.append(chess_dict[term])\n",
    "                    rows.append(terms)\n",
    "                return rows\n",
    "            for i in range(len(agents)-1):\n",
    "                player = [0]*2\n",
    "                player[0] = agents[i]\n",
    "                player[1] = agents[i+1]\n",
    "\n",
    "                board = chess.Board()\n",
    "                while not(board.is_game_over()):           \n",
    "                    matrix = make_matrix(board)\n",
    "                    X = np.reshape(np.array(translate(matrix,chess_dict)),(1,8,8,12))\n",
    "                    if i % 2 == 0:\n",
    "                        player_index = 0\n",
    "                    else:\n",
    "                        player_index = 1\n",
    "                    move_ratio = player[player_index].neural_network.propagate(X)\n",
    "                    legal_moves = str(board.legal_moves)[36:-2].replace(',','').split()\n",
    "                    index = int(move_ratio * len(legal_moves))\n",
    "                    board.push_san(legal_moves[index])\n",
    "\n",
    "                def evaluate_score(board):\n",
    "                    player_fitness = [0]*2\n",
    "                    sides = [True,False]\n",
    "                    result = board.result()\n",
    "                    if result == '1/2-1/2':\n",
    "                        player_fitness[0] += 10\n",
    "                        player_fitness[1] += 10\n",
    "                    elif result == '1-0':\n",
    "                        player_fitness[0] += 100\n",
    "                        player_fitness[1] -= 100\n",
    "                    elif result == '0-1':\n",
    "                        player_fitness[0] -= 100\n",
    "                        player_fitness[1] += 100\n",
    "                    def calculate_material(board,side):\n",
    "                        material = 0\n",
    "                        material_values = [1,3,3,5,6,0]\n",
    "                        for i in range(1,7):\n",
    "                            count = len(board.pieces(i,side))\n",
    "                            material += count*material_values[i-1]\n",
    "                        return material\n",
    "                    for i in range(2):\n",
    "                        player_fitness[i] += calculate_material(board,sides[i])\n",
    "                    return player_fitness\n",
    "    #                 for i in range(2):\n",
    "    #                     sides[0]\n",
    "                def calculate_material(board,side):\n",
    "                    material = 0\n",
    "                    material_values = [1,3,3,5,6,0]\n",
    "                    for i in range(1,7):\n",
    "                        board = chess.Board()\n",
    "                        count = len(board.pieces(i,side))\n",
    "                        material += count*material_values[i-1]\n",
    "                    return material\n",
    "                fitnesses = evaluate_score(board)\n",
    "                player[0].fitness += fitnesses[0]\n",
    "                player[1].fitness += fitnesses[1]\n",
    "            return agents\n",
    "        \n",
    "        def selection(agents):\n",
    "            agents = sorted(agents, key=lambda agent: agent.fitness, reverse=True)\n",
    "            print('\\n'.join(map(str, agents)))\n",
    "            agents = agents[:int(0.2 * len(agents))]\n",
    "            return agents\n",
    "        \n",
    "        def unflatten(flattened,shapes):\n",
    "            newarray = []\n",
    "            index = 0\n",
    "            for shape in shapes:\n",
    "                size = np.product(shape)\n",
    "                newarray.append(flattened[index : index + size].reshape(shape))\n",
    "                index += size\n",
    "            return newarray\n",
    "        \n",
    "        def crossover(agents,pop_size):\n",
    "            offspring = []\n",
    "            for _ in range((pop_size - len(agents)) // 2):\n",
    "                parent1 = random.choice(agents)\n",
    "                parent2 = random.choice(agents)\n",
    "                child1 = Agent()\n",
    "                child2 = Agent()\n",
    "                        \n",
    "                \n",
    "                shapes = [a.shape for a in parent1.neural_network.weights]\n",
    "                \n",
    "                genes1 = np.concatenate([a.flatten() for a in parent1.neural_network.weights])\n",
    "                genes2 = np.concatenate([a.flatten() for a in parent2.neural_network.weights])\n",
    "                \n",
    "                split = random.randint(0,len(genes1)-1)\n",
    "\n",
    "                child1_genes = np.array(genes1[0:split].tolist() + genes2[split:].tolist())\n",
    "                child2_genes = np.array(genes1[0:split].tolist() + genes2[split:].tolist())\n",
    "                \n",
    "                child1.neural_network.weights = unflatten(child1_genes,shapes)\n",
    "                child2.neural_network.weights = unflatten(child2_genes,shapes)\n",
    "                \n",
    "                offspring.append(child1)\n",
    "                offspring.append(child2)\n",
    "            agents.extend(offspring)\n",
    "            return agents\n",
    "        \n",
    "        def mutation(agents):\n",
    "            for agent in agents:\n",
    "                if random.uniform(0.0, 1.0) <= 0.1:\n",
    "                    weights = agent.neural_network.weights\n",
    "                    shapes = [a.shape for a in weights]\n",
    "\n",
    "                    flattened = np.concatenate([a.flatten() for a in weights])\n",
    "                    randint = random.randint(0,len(flattened)-1)\n",
    "                    flattened[randint] = np.random.randn()\n",
    "\n",
    "                    newarray = []\n",
    "                    indeweights = 0\n",
    "                    for shape in shapes:\n",
    "                        size = np.product(shape)\n",
    "                        newarray.append(flattened[indeweights : indeweights + size].reshape(shape))\n",
    "                        indeweights += size\n",
    "                    agent.neural_network.weights = newarray\n",
    "            return agents\n",
    "        \n",
    "        for i in range(generations):\n",
    "            print('Generation',str(i),':')\n",
    "            agents = generate_agents(pop_size)\n",
    "            agents = fitness(agents)\n",
    "            agents = selection(agents)\n",
    "            agents = crossover(agents,pop_size)\n",
    "            agents = mutation(agents)\n",
    "            agents = fitness(agents)\n",
    "            \n",
    "            if any(agent.fitness > threshold for agent in agents):\n",
    "                print('Threshold met at generation '+str(i)+' !')\n",
    "                break\n",
    "                \n",
    "            clear_output()\n",
    "        return agents[0]\n",
    "ga = genetic_algorithm\n",
    "agent = ga.execute(10,100,1000)\n",
    "weights = agent.neural_network.weights\n",
    "agent.fitness\n",
    "# agent.neural_network.propagate(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T17:37:01.290714Z",
     "start_time": "2020-08-31T17:37:01.188924Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D,MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(64,input_shape = (8,8,12)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T17:38:12.547102Z",
     "start_time": "2020-08-31T17:38:11.924684Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 8, 8, 64)          832       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12)                49164     \n",
      "=================================================================\n",
      "Total params: 49,996\n",
      "Trainable params: 49,996\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.21450955,\n",
       " 0.1818482,\n",
       " -0.1324994,\n",
       " -0.25583774,\n",
       " 0.0493598,\n",
       " 0.05355555,\n",
       " 0.20013991,\n",
       " -0.24384427,\n",
       " -0.012229383,\n",
       " 0.2235882,\n",
       " -0.11038625,\n",
       " 0.14760098,\n",
       " 0.098683715,\n",
       " -0.17381021,\n",
       " -0.0992374,\n",
       " 0.16306439,\n",
       " -0.17835775,\n",
       " 0.026804566,\n",
       " -0.27202824,\n",
       " 0.121613085,\n",
       " -0.11826512,\n",
       " 0.03431046,\n",
       " 0.13060585,\n",
       " 0.06888035,\n",
       " -0.25016183,\n",
       " -0.27283928,\n",
       " 0.17743525,\n",
       " -0.12338321,\n",
       " 0.0755918,\n",
       " 0.08405343,\n",
       " -0.18141201,\n",
       " -0.11137736,\n",
       " -0.05098127,\n",
       " -0.20983675,\n",
       " 0.21638131,\n",
       " -0.24936758,\n",
       " 0.11406052,\n",
       " -0.0061074495,\n",
       " 0.059082568,\n",
       " -0.24442427,\n",
       " 0.20246285,\n",
       " 0.053631783,\n",
       " 0.050997138,\n",
       " -0.073615596,\n",
       " -0.16772225,\n",
       " -0.001665622,\n",
       " 0.15725228,\n",
       " -0.02888292,\n",
       " -0.1183784,\n",
       " -0.08571583,\n",
       " 0.13167039,\n",
       " -0.2214,\n",
       " 0.082980365,\n",
       " -0.038496777,\n",
       " -0.031651765,\n",
       " -0.20236558,\n",
       " 0.27080336,\n",
       " -0.03734073,\n",
       " 0.22809723,\n",
       " 0.22005764,\n",
       " -0.17088443,\n",
       " 0.1034995,\n",
       " -0.111451656,\n",
       " -0.2707971,\n",
       " 0.19642001,\n",
       " 0.12574843,\n",
       " -0.10187727,\n",
       " 0.257984,\n",
       " 0.06745836,\n",
       " 0.16828254,\n",
       " -0.052120507,\n",
       " 0.1842775,\n",
       " 0.22747967,\n",
       " -0.053727314,\n",
       " -0.17121255,\n",
       " 0.15069023,\n",
       " -0.21651074,\n",
       " -0.044107452,\n",
       " -0.21139032,\n",
       " 0.016049087,\n",
       " 0.019527793,\n",
       " 0.2158882,\n",
       " 0.2667856,\n",
       " -0.14052378,\n",
       " -0.06852162,\n",
       " 0.14159581,\n",
       " -0.16477208,\n",
       " -0.18975928,\n",
       " -0.2079264,\n",
       " -0.021361858,\n",
       " -0.18699649,\n",
       " -0.14884096,\n",
       " -0.27418724,\n",
       " 0.019934028,\n",
       " 0.009047121,\n",
       " -0.04792513,\n",
       " 0.09385055,\n",
       " -0.27931222,\n",
       " 0.119687796,\n",
       " -0.081983626,\n",
       " -0.23168716,\n",
       " 0.22630915,\n",
       " -0.26040584,\n",
       " 0.15084597,\n",
       " 0.21666831,\n",
       " -0.2751298,\n",
       " -0.03934802,\n",
       " 0.01608318,\n",
       " -0.047618657,\n",
       " 0.2209355,\n",
       " 0.25548866,\n",
       " -0.1589037,\n",
       " 0.014998078,\n",
       " 0.04414937,\n",
       " -0.2807156,\n",
       " 0.15220326,\n",
       " 0.06449613,\n",
       " 0.15880576,\n",
       " -0.21446106,\n",
       " -0.1841821,\n",
       " 0.18533427,\n",
       " -0.21784551,\n",
       " 0.26224706,\n",
       " 0.07828471,\n",
       " -0.111246005,\n",
       " -0.25215122,\n",
       " 0.2604272,\n",
       " 0.111482084,\n",
       " 0.25340614,\n",
       " -0.2714777,\n",
       " 0.16973147,\n",
       " -0.2744412,\n",
       " -0.2154826,\n",
       " -0.2566824,\n",
       " 0.028517246,\n",
       " -0.19425665,\n",
       " -0.27944797,\n",
       " 0.03668061,\n",
       " -0.1189304,\n",
       " 0.087204814,\n",
       " 0.09154135,\n",
       " 0.17157242,\n",
       " 0.12902758,\n",
       " 0.028983831,\n",
       " -0.06865011,\n",
       " -0.23773667,\n",
       " -0.24869052,\n",
       " 0.12158629,\n",
       " -0.10726084,\n",
       " -0.17522693,\n",
       " 0.09475237,\n",
       " -0.0054405034,\n",
       " 0.00050356984,\n",
       " -0.22180213,\n",
       " -0.2642964,\n",
       " 0.03868997,\n",
       " -0.122678146,\n",
       " -0.053093597,\n",
       " -0.018164754,\n",
       " -0.20123237,\n",
       " -0.2681339,\n",
       " 0.09512985,\n",
       " -0.23681918,\n",
       " 0.17865652,\n",
       " 0.23653165,\n",
       " -0.15204817,\n",
       " -0.116678745,\n",
       " 0.2587373,\n",
       " -0.18852246,\n",
       " 0.02777043,\n",
       " -0.17187126,\n",
       " 0.20045918,\n",
       " 0.2775052,\n",
       " -0.17680246,\n",
       " 0.1395326,\n",
       " -0.106090665,\n",
       " -0.18927228,\n",
       " 0.1646314,\n",
       " 0.2396501,\n",
       " 0.25653884,\n",
       " 0.038320392,\n",
       " 0.052939117,\n",
       " -0.07620375,\n",
       " 0.14523757,\n",
       " 0.1679683,\n",
       " 0.09359303,\n",
       " 0.13066924,\n",
       " -0.23175682,\n",
       " 0.15264204,\n",
       " -0.02381885,\n",
       " 0.1083495,\n",
       " -0.17072326,\n",
       " 0.06387547,\n",
       " -0.24512471,\n",
       " -0.114472896,\n",
       " -0.1942417,\n",
       " 0.15335721,\n",
       " 0.21877292,\n",
       " 0.0021207035,\n",
       " 0.21762532,\n",
       " 0.10175809,\n",
       " -0.08516364,\n",
       " -0.24422504,\n",
       " 0.17932174,\n",
       " 0.25647035,\n",
       " 0.10758546,\n",
       " -0.2357042,\n",
       " 0.23816672,\n",
       " 0.03743854,\n",
       " -0.042503312,\n",
       " -0.1648019,\n",
       " -0.25712895,\n",
       " 0.1508303,\n",
       " -0.022467583,\n",
       " 0.24797586,\n",
       " 0.08506054,\n",
       " -0.24292597,\n",
       " -0.0023788214,\n",
       " -0.16888091,\n",
       " 0.19312659,\n",
       " 0.116972685,\n",
       " 0.23463878,\n",
       " -0.017370135,\n",
       " -0.14426114,\n",
       " -0.0041571856,\n",
       " -0.011053532,\n",
       " 0.26313606,\n",
       " -0.06322132,\n",
       " -0.09658192,\n",
       " -0.06918818,\n",
       " 0.07161668,\n",
       " -0.10613963,\n",
       " 0.117444366,\n",
       " 0.17494711,\n",
       " 0.22971949,\n",
       " 0.11668825,\n",
       " 0.20055377,\n",
       " 0.1527395,\n",
       " -0.001570642,\n",
       " 0.04330945,\n",
       " 0.021247357,\n",
       " 0.23566589,\n",
       " -0.10252653,\n",
       " -0.018347591,\n",
       " 0.075930685,\n",
       " -0.13072014,\n",
       " -0.04608445,\n",
       " -0.186231,\n",
       " 0.11918101,\n",
       " -0.030492574,\n",
       " 0.19135296,\n",
       " -0.0035025775,\n",
       " -0.2560636,\n",
       " -0.007438153,\n",
       " -0.20539123,\n",
       " 0.28089634,\n",
       " 0.22469756,\n",
       " 0.04919681,\n",
       " 0.068179846,\n",
       " 0.021064967,\n",
       " 0.15476894,\n",
       " -0.097757265,\n",
       " 0.044826984,\n",
       " -0.16924413,\n",
       " 0.03131762,\n",
       " 0.076880276,\n",
       " -0.028893858,\n",
       " -0.20006862,\n",
       " 0.14472309,\n",
       " 0.081433564,\n",
       " 0.041258246,\n",
       " 0.10729179,\n",
       " -0.2648796,\n",
       " -0.0060069263,\n",
       " -0.27591223,\n",
       " -0.16596001,\n",
       " -0.095801964,\n",
       " 0.061393976,\n",
       " 0.08073065,\n",
       " -0.080835834,\n",
       " 0.0660162,\n",
       " -0.13451888,\n",
       " 0.20080042,\n",
       " -0.21677797,\n",
       " 0.03612092,\n",
       " -0.01450637,\n",
       " -0.22469643,\n",
       " 0.09667337,\n",
       " -0.19319044,\n",
       " -0.19692594,\n",
       " -0.23331761,\n",
       " -0.163292,\n",
       " -0.22551364,\n",
       " -0.25102022,\n",
       " 0.17715856,\n",
       " -0.04127364,\n",
       " 0.18722391,\n",
       " 0.015829772,\n",
       " -0.27582654,\n",
       " -0.16917667,\n",
       " 0.14812738,\n",
       " 0.18836972,\n",
       " -0.21674956,\n",
       " -0.23766567,\n",
       " 0.14909706,\n",
       " 0.1604586,\n",
       " 0.031107396,\n",
       " 0.07640043,\n",
       " -0.0049865246,\n",
       " 0.015287697,\n",
       " 0.21662778,\n",
       " 0.08025488,\n",
       " -0.27247974,\n",
       " -0.24728252,\n",
       " 0.13149494,\n",
       " -0.13944496,\n",
       " -0.23915243,\n",
       " -0.111206606,\n",
       " -0.009768516,\n",
       " -0.22084424,\n",
       " -0.09248771,\n",
       " 0.15072498,\n",
       " 0.23727748,\n",
       " 0.28039327,\n",
       " -0.19382551,\n",
       " 0.006473303,\n",
       " 0.11298156,\n",
       " -0.1258213,\n",
       " 0.23033378,\n",
       " 0.05518529,\n",
       " -0.050415203,\n",
       " -0.19319981,\n",
       " -0.145408,\n",
       " -0.10729554,\n",
       " -0.046705917,\n",
       " -0.07153757,\n",
       " 0.14137703,\n",
       " -0.005323738,\n",
       " 0.1595661,\n",
       " -0.19553536,\n",
       " 0.12535957,\n",
       " -0.13524537,\n",
       " -0.11594701,\n",
       " 0.020970553,\n",
       " -0.040489793,\n",
       " -0.10694277,\n",
       " 0.2790809,\n",
       " -0.15906247,\n",
       " -0.22423688,\n",
       " -0.19154096,\n",
       " -0.10951103,\n",
       " -0.15082145,\n",
       " -0.24306545,\n",
       " 0.08013278,\n",
       " -0.051928982,\n",
       " -0.14258458,\n",
       " -0.2394845,\n",
       " -0.17402437,\n",
       " 0.22722271,\n",
       " 0.016280472,\n",
       " -0.24946451,\n",
       " -0.060838893,\n",
       " 0.27892885,\n",
       " 0.055302173,\n",
       " -0.1295434,\n",
       " -0.1698749,\n",
       " 0.17260814,\n",
       " -0.054801434,\n",
       " 0.16058514,\n",
       " 0.04799646,\n",
       " 0.21662885,\n",
       " 0.11616191,\n",
       " 0.14980221,\n",
       " -0.0011707246,\n",
       " -0.27579528,\n",
       " -0.15370885,\n",
       " 0.17938712,\n",
       " 0.10140875,\n",
       " -0.18479173,\n",
       " -0.16818234,\n",
       " -0.07253325,\n",
       " -0.000860095,\n",
       " 0.22673514,\n",
       " -0.045875907,\n",
       " -0.2530172,\n",
       " -0.28000733,\n",
       " -0.1033556,\n",
       " 0.27117452,\n",
       " 0.019183755,\n",
       " 0.2389563,\n",
       " 0.03179097,\n",
       " -0.09774621,\n",
       " 0.27733508,\n",
       " 0.16394013,\n",
       " -0.23023522,\n",
       " -0.24863224,\n",
       " 0.17573851,\n",
       " -0.18440956,\n",
       " -0.029614598,\n",
       " -0.17568111,\n",
       " 0.1891531,\n",
       " -0.20515248,\n",
       " -0.2268113,\n",
       " -0.061203793,\n",
       " 0.08655676,\n",
       " -0.16910344,\n",
       " 0.07814103,\n",
       " 0.22362718,\n",
       " -0.12888362,\n",
       " 0.10334179,\n",
       " 0.009141028,\n",
       " 0.24314424,\n",
       " -0.26794285,\n",
       " -0.2393508,\n",
       " -0.27687362,\n",
       " 0.1469574,\n",
       " 0.12409893,\n",
       " -0.18981135,\n",
       " 0.047842383,\n",
       " 0.17862001,\n",
       " 0.28007534,\n",
       " -0.24620995,\n",
       " 0.053444564,\n",
       " 0.028864503,\n",
       " -0.26225695,\n",
       " -0.14319405,\n",
       " -0.016583055,\n",
       " 0.10588434,\n",
       " 0.25307325,\n",
       " 0.2632707,\n",
       " 0.26384947,\n",
       " 0.040870637,\n",
       " 0.15876779,\n",
       " 0.107277244,\n",
       " -0.26335827,\n",
       " 0.08224055,\n",
       " 0.2015371,\n",
       " -0.11818239,\n",
       " 0.25928912,\n",
       " 0.0324547,\n",
       " 0.121079564,\n",
       " -0.21242732,\n",
       " -0.08369696,\n",
       " 0.0049341917,\n",
       " -0.21529153,\n",
       " 0.06774855,\n",
       " -0.015423685,\n",
       " -0.25348738,\n",
       " -0.22602972,\n",
       " -0.13697593,\n",
       " -0.2398001,\n",
       " 0.01489833,\n",
       " -0.24454646,\n",
       " 0.048604935,\n",
       " 0.0010930598,\n",
       " -0.081857026,\n",
       " 0.13661024,\n",
       " -0.18423143,\n",
       " -0.22243552,\n",
       " 0.09119749,\n",
       " -0.22784348,\n",
       " 0.06390193,\n",
       " -0.06858352,\n",
       " 0.13608363,\n",
       " -0.13687423,\n",
       " 0.23517135,\n",
       " 0.22448435,\n",
       " 0.22879174,\n",
       " 0.17068133,\n",
       " -0.2387592,\n",
       " 0.24845013,\n",
       " 0.056388617,\n",
       " 0.11345023,\n",
       " -0.15890309,\n",
       " 0.13771945,\n",
       " 0.17875057,\n",
       " -0.14104784,\n",
       " 0.06216207,\n",
       " -0.04715489,\n",
       " -0.13987035,\n",
       " 0.25297526,\n",
       " 0.184822,\n",
       " 0.21196863,\n",
       " -0.1978804,\n",
       " -0.12656161,\n",
       " 0.19855982,\n",
       " 0.20339218,\n",
       " -0.15085997,\n",
       " -0.280697,\n",
       " -0.13522775,\n",
       " -0.018574864,\n",
       " 0.08184323,\n",
       " 0.25664225,\n",
       " -0.2558177,\n",
       " -0.034607217,\n",
       " 0.021694064,\n",
       " 0.21256691,\n",
       " 0.060765266,\n",
       " -0.16608019,\n",
       " -0.17926915,\n",
       " 0.096759796,\n",
       " 0.14571252,\n",
       " -0.05830574,\n",
       " 0.15166539,\n",
       " 0.23810509,\n",
       " 0.22385505,\n",
       " -0.018743634,\n",
       " -0.078502834,\n",
       " -0.2592049,\n",
       " 0.17601591,\n",
       " 0.08635008,\n",
       " 0.037725717,\n",
       " -0.10382117,\n",
       " 0.17495227,\n",
       " 0.02055657,\n",
       " -0.0116330385,\n",
       " -0.14002176,\n",
       " -0.174803,\n",
       " -0.26995638,\n",
       " -0.18327467,\n",
       " 0.24498966,\n",
       " -0.16945213,\n",
       " -0.2535706,\n",
       " -0.17199412,\n",
       " 0.26173505,\n",
       " 0.12742525,\n",
       " 0.0021663904,\n",
       " 0.009455025,\n",
       " 0.00092720985,\n",
       " -0.16936898,\n",
       " 0.2721304,\n",
       " -0.22694488,\n",
       " -0.2259888,\n",
       " 0.08042237,\n",
       " -0.19674124,\n",
       " 0.24706551,\n",
       " 0.077780366,\n",
       " 0.26129028,\n",
       " -0.21038619,\n",
       " -0.105280355,\n",
       " 0.07470882,\n",
       " 0.13863319,\n",
       " -0.09043446,\n",
       " -0.24783927,\n",
       " -0.15247603,\n",
       " 0.08953881,\n",
       " 0.07586512,\n",
       " 0.02612263,\n",
       " -0.268939,\n",
       " 0.24565753,\n",
       " -0.1939917,\n",
       " -0.26043692,\n",
       " -0.24865761,\n",
       " 0.23833254,\n",
       " -0.27814212,\n",
       " -0.17958254,\n",
       " 0.09520146,\n",
       " -0.034118652,\n",
       " -0.18849835,\n",
       " 0.20415086,\n",
       " -0.13149206,\n",
       " -0.15609944,\n",
       " 0.19892773,\n",
       " 0.1833789,\n",
       " 0.20118085,\n",
       " -0.1551449,\n",
       " -0.10944678,\n",
       " 0.15831119,\n",
       " 0.13642332,\n",
       " -0.15386459,\n",
       " -0.051576406,\n",
       " 0.15768316,\n",
       " -0.024686277,\n",
       " 0.24777159,\n",
       " 0.12306675,\n",
       " 0.1040391,\n",
       " -0.06206213,\n",
       " 0.17855692,\n",
       " 0.077340424,\n",
       " 0.08366507,\n",
       " -0.08750212,\n",
       " 0.27310023,\n",
       " 0.26675263,\n",
       " -0.2359812,\n",
       " -0.024011761,\n",
       " -0.24021322,\n",
       " -0.22705434,\n",
       " -0.21737632,\n",
       " 0.07600257,\n",
       " -0.14207558,\n",
       " 0.13193968,\n",
       " 0.20459983,\n",
       " 0.2503051,\n",
       " 0.06469756,\n",
       " 0.16505626,\n",
       " -0.10140981,\n",
       " 0.03526339,\n",
       " 0.06496614,\n",
       " -0.18283375,\n",
       " 0.1310583,\n",
       " -0.121561155,\n",
       " -0.058394432,\n",
       " 0.05816552,\n",
       " -0.25574616,\n",
       " 0.14733776,\n",
       " 0.18297169,\n",
       " -0.12647721,\n",
       " 0.2641804,\n",
       " -0.20532632,\n",
       " -0.08239442,\n",
       " -0.16540769,\n",
       " -0.2539107,\n",
       " -0.24685714,\n",
       " -0.049435556,\n",
       " -0.12272845,\n",
       " -0.040420666,\n",
       " 0.04480228,\n",
       " -0.17812154,\n",
       " 0.2754695,\n",
       " -0.07051243,\n",
       " 0.26326016,\n",
       " 0.011515409,\n",
       " -0.08983001,\n",
       " 0.02992484,\n",
       " -0.0047923923,\n",
       " -0.25823173,\n",
       " -0.20020267,\n",
       " -0.14368716,\n",
       " 0.22440866,\n",
       " -0.24362521,\n",
       " 0.024803847,\n",
       " 0.09689897,\n",
       " 0.12880355,\n",
       " 0.09171975,\n",
       " 0.26754597,\n",
       " -0.2621122,\n",
       " 0.057617366,\n",
       " -0.21346357,\n",
       " 0.23061648,\n",
       " -0.13633603,\n",
       " -0.13753067,\n",
       " -0.26667964,\n",
       " 0.121778876,\n",
       " 0.25911173,\n",
       " 0.25052652,\n",
       " -0.037201807,\n",
       " 0.0030434132,\n",
       " -0.23831567,\n",
       " 0.20905101,\n",
       " 0.13412023,\n",
       " 0.043910503,\n",
       " 0.08905682,\n",
       " 0.07826877,\n",
       " -0.19022761,\n",
       " 0.14577612,\n",
       " 0.24361607,\n",
       " -0.074847266,\n",
       " -0.12692657,\n",
       " 0.104533136,\n",
       " 0.07620925,\n",
       " 0.07234982,\n",
       " 0.07485351,\n",
       " 0.11239803,\n",
       " 0.22608784,\n",
       " -0.2563429,\n",
       " -0.16495101,\n",
       " -0.031068206,\n",
       " 0.114919394,\n",
       " -0.02183479,\n",
       " 0.26343235,\n",
       " 0.12797785,\n",
       " 0.021233708,\n",
       " -0.04715568,\n",
       " 0.17301202,\n",
       " 0.059134334,\n",
       " -0.11878838,\n",
       " -0.19522935,\n",
       " 0.14603099,\n",
       " -0.16529728,\n",
       " 0.2498124,\n",
       " -0.21758968,\n",
       " -0.20247725,\n",
       " 0.094156235,\n",
       " -0.20803961,\n",
       " 0.0627169,\n",
       " -0.20049188,\n",
       " -0.013812035,\n",
       " 0.22923061,\n",
       " -0.11280277,\n",
       " -0.064718276,\n",
       " -0.041660443,\n",
       " -0.26387933,\n",
       " -0.21273592,\n",
       " 0.18333596,\n",
       " 0.009972304,\n",
       " 0.21227035,\n",
       " 0.033483535,\n",
       " -0.26835138,\n",
       " -0.061130494,\n",
       " -0.04997146,\n",
       " -0.20478866,\n",
       " -0.18423724,\n",
       " -0.17609236,\n",
       " 0.10111913,\n",
       " 0.21991745,\n",
       " -0.09382965,\n",
       " -0.16263564,\n",
       " 0.27263752,\n",
       " -0.08585203,\n",
       " 0.09423721,\n",
       " -0.022071868,\n",
       " -0.11732687,\n",
       " 0.27476642,\n",
       " 0.19314349,\n",
       " 0.19423509,\n",
       " -0.111231536,\n",
       " 0.10453844,\n",
       " 0.051213056,\n",
       " 0.21521926,\n",
       " -0.27310997,\n",
       " -0.17959693,\n",
       " 0.12931049,\n",
       " -0.15407863,\n",
       " 0.114697784,\n",
       " -0.06707397,\n",
       " -0.26550034,\n",
       " -0.15733983,\n",
       " 0.12850848,\n",
       " 0.051698267,\n",
       " -0.0018620491,\n",
       " 0.085706264,\n",
       " -0.18680517,\n",
       " 0.076343894,\n",
       " -0.18622021,\n",
       " 0.053988636,\n",
       " -0.102943406,\n",
       " 0.20406035,\n",
       " -0.21913722,\n",
       " -0.26111498,\n",
       " 0.2263712,\n",
       " -0.26915315,\n",
       " 0.12500289,\n",
       " 0.11973575,\n",
       " 0.12712318,\n",
       " 0.14094132,\n",
       " -0.23380591,\n",
       " -0.20955418,\n",
       " -0.20614205,\n",
       " -0.102697566,\n",
       " -0.13749483,\n",
       " 0.10365236,\n",
       " 0.124628425,\n",
       " -0.007509172,\n",
       " -0.170295,\n",
       " 0.23189947,\n",
       " -0.18933444,\n",
       " 0.20984304,\n",
       " 0.15999785,\n",
       " -0.20414126,\n",
       " 0.0770278,\n",
       " 0.22474232,\n",
       " -0.07881193,\n",
       " -0.10031922,\n",
       " -0.12653737,\n",
       " -0.018586785,\n",
       " 0.09378114,\n",
       " -0.054204687,\n",
       " 0.00050732493,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.030415088,\n",
       " -0.001954317,\n",
       " -0.024884507,\n",
       " 0.02882684,\n",
       " 0.011306182,\n",
       " -0.00693395,\n",
       " -0.015530923,\n",
       " -0.026306026,\n",
       " 0.027035668,\n",
       " -0.015640527,\n",
       " -0.014068609,\n",
       " -0.007980995,\n",
       " -0.0295659,\n",
       " 0.03255962,\n",
       " 0.03501746,\n",
       " -0.034225553,\n",
       " -0.0141332485,\n",
       " 0.013706382,\n",
       " 0.003165841,\n",
       " -0.029905967,\n",
       " -0.009160835,\n",
       " 0.009001892,\n",
       " -0.02776568,\n",
       " 0.009316292,\n",
       " 0.035862394,\n",
       " 0.027571552,\n",
       " -0.031718854,\n",
       " -0.024658073,\n",
       " 0.018919118,\n",
       " 0.013533961,\n",
       " -0.02847592,\n",
       " -0.015409445,\n",
       " 0.034111947,\n",
       " 0.026126534,\n",
       " 0.03713376,\n",
       " 0.003072016,\n",
       " 0.01682723,\n",
       " 0.00569693,\n",
       " -0.03216751,\n",
       " 0.0051885433,\n",
       " 0.03553565,\n",
       " 0.003135983,\n",
       " -0.03786505,\n",
       " -0.0012574904,\n",
       " 0.033099726,\n",
       " 0.0077759996,\n",
       " 0.003673263,\n",
       " 0.028715104,\n",
       " -0.0181634,\n",
       " -0.009692641,\n",
       " -0.0014753528,\n",
       " 0.028977372,\n",
       " -0.021033155,\n",
       " 0.0031860508,\n",
       " 0.020690601,\n",
       " -0.010507911,\n",
       " -0.034377363,\n",
       " -0.016857034,\n",
       " 0.004229717,\n",
       " -0.011416979,\n",
       " 0.026677221,\n",
       " 0.005558133,\n",
       " 0.006741762,\n",
       " -0.0017289221,\n",
       " 0.036148213,\n",
       " 0.025807254,\n",
       " -0.015400862,\n",
       " -0.0363146,\n",
       " 0.011083309,\n",
       " -0.021648323,\n",
       " 0.020792715,\n",
       " -0.003475722,\n",
       " 0.024710089,\n",
       " -0.020836305,\n",
       " -0.02079891,\n",
       " 0.0068110675,\n",
       " 0.026610732,\n",
       " 0.023281373,\n",
       " -0.008858252,\n",
       " -0.032200098,\n",
       " 0.01847341,\n",
       " 0.035972767,\n",
       " 0.02142812,\n",
       " -0.027419407,\n",
       " -0.025938788,\n",
       " 0.02131809,\n",
       " 0.000843361,\n",
       " -0.007510729,\n",
       " -0.029697483,\n",
       " -0.023699263,\n",
       " -0.026641648,\n",
       " -0.019763455,\n",
       " -0.01966256,\n",
       " -0.03783264,\n",
       " -0.0065040477,\n",
       " 0.0015947521,\n",
       " -0.03800638,\n",
       " 0.027742773,\n",
       " -0.016301638,\n",
       " 0.007015161,\n",
       " -0.015603816,\n",
       " -0.014368741,\n",
       " 0.011923775,\n",
       " 0.021642737,\n",
       " -0.016554797,\n",
       " 0.0338424,\n",
       " 0.037669137,\n",
       " 0.021931853,\n",
       " -0.035355646,\n",
       " 0.020531546,\n",
       " 0.018351521,\n",
       " -0.0070215575,\n",
       " -0.0057183728,\n",
       " -0.01774878,\n",
       " -0.031250704,\n",
       " -0.023316178,\n",
       " 0.008242447,\n",
       " 0.013535764,\n",
       " 0.005470231,\n",
       " -0.013803996,\n",
       " 0.038141616,\n",
       " -0.012993945,\n",
       " 0.030913882,\n",
       " 0.02359714,\n",
       " -0.015450494,\n",
       " 0.021992873,\n",
       " 0.03717994,\n",
       " -0.023014728,\n",
       " 0.01031794,\n",
       " 0.009155776,\n",
       " 0.025499932,\n",
       " -0.028789055,\n",
       " 0.030361347,\n",
       " 0.012656257,\n",
       " -0.02666821,\n",
       " 0.034809217,\n",
       " -0.02264132,\n",
       " 0.03795401,\n",
       " 0.0074962527,\n",
       " 0.014912009,\n",
       " -0.0237113,\n",
       " -0.005324643,\n",
       " -0.0010533892,\n",
       " -0.013035696,\n",
       " 0.007530965,\n",
       " 0.006576795,\n",
       " -0.034821022,\n",
       " 0.030543424,\n",
       " 0.030243002,\n",
       " 0.020557687,\n",
       " 0.031946354,\n",
       " -0.008065816,\n",
       " 0.030003645,\n",
       " 0.022834625,\n",
       " 0.015999768,\n",
       " -0.012817569,\n",
       " -0.011958297,\n",
       " -0.031117026,\n",
       " 0.0033185072,\n",
       " -0.026880238,\n",
       " -0.023842955,\n",
       " 0.029799864,\n",
       " -0.0026655085,\n",
       " 0.01637251,\n",
       " 0.032195464,\n",
       " -0.02347907,\n",
       " -0.019054772,\n",
       " 0.01783485,\n",
       " ...)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()\n",
    "weights = model.get_weights()\n",
    "flatten(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T17:38:03.603097Z",
     "start_time": "2020-08-31T17:38:03.597786Z"
    }
   },
   "outputs": [],
   "source": [
    "def flatten(itr):\n",
    "    t = tuple()\n",
    "    for e in itr:\n",
    "        try:\n",
    "            t += flatten(e)\n",
    "        except:\n",
    "            t += (e,)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-30T09:10:05.646285Z",
     "start_time": "2020-08-30T09:10:05.635592Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 3, 12, 64), (64,), (3, 3, 64, 64), (64,), (256, 12), (12,)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-30T09:19:29.515283Z",
     "start_time": "2020-08-30T09:19:28.562479Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float32' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-032bb2034215>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-032bb2034215>\u001b[0m in \u001b[0;36mflatten\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# flatten nested lists of np.ndarray to np.ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprototype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-032bb2034215>\u001b[0m in \u001b[0;36m_flatten\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-032bb2034215>\u001b[0m in \u001b[0;36m_flatten\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float32' object is not iterable"
     ]
    }
   ],
   "source": [
    "def _flatten(values):\n",
    "    if isinstance(values, np.ndarray):\n",
    "        yield values.flatten()\n",
    "    else:\n",
    "        for value in values:\n",
    "            yield from _flatten(value)\n",
    "\n",
    "def flatten(values):\n",
    "    # flatten nested lists of np.ndarray to np.ndarray\n",
    "    return np.concatenate(list(_flatten(values)))\n",
    "\n",
    "def _unflatten(flat_values, prototype, offset):\n",
    "    if isinstance(prototype, np.ndarray):\n",
    "        shape = prototype.shape\n",
    "        new_offset = offset + np.product(shape)\n",
    "        value = flat_values[offset:new_offset].reshape(shape)\n",
    "        return value, new_offset\n",
    "    else:\n",
    "        result = []\n",
    "        for value in prototype:\n",
    "            value, offset = _unflatten(flat_values, value, offset)\n",
    "            result.append(value)\n",
    "        return result, offset\n",
    "\n",
    "def unflatten(flat_values, prototype):\n",
    "    # unflatten np.ndarray to nested lists with structure of prototype\n",
    "    result, offset = _unflatten(flat_values, prototype, 0)\n",
    "    assert(offset == len(flat_values))\n",
    "    return result\n",
    "\n",
    "flatten(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T18:26:28.023082Z",
     "start_time": "2020-08-31T18:26:28.014522Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "board = chess.Board()\n",
    "len(board.pieces(1,True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
